{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661612df-5e84-4ebd-847a-ef136d1f1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc9d8c8-1cf0-4528-aad0-c01f1fb25086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from utils import neo4j_driver, num_tokens_from_string, chunk_text, chat\n",
    "import ch07_tools\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e4999c-e98d-499e-89d5-e7d1730e7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/1727/pg1727.txt\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9335794-0cc6-4d98-b10a-9f7d4b5c0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_into_books(text: str) -> List[str]:\n",
    "    return text.split(\"PREFACE TO FIRST EDITION\")[2].split(\"FOOTNOTES\")[0].strip().split(\"\\nBOOK\")[1:]\n",
    "\n",
    "books = chunk_into_books(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddeadc3-e491-49ba-8af7-f38fdfd8e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 books with token sizes:\n",
      "- avg 6515.208333333333\n",
      "- min 4459\n",
      "- max 10760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_count = [num_tokens_from_string(el) for el in books]\n",
    "print(f\"\"\"There are {len(token_count)} books with token sizes:\n",
    "- avg {sum(token_count) / len(token_count)}\n",
    "- min {min(token_count)}\n",
    "- max {max(token_count)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d74c7143-2357-4f05-abc6-b6f18a229cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_books = [chunk_text(book, 1000, 40) for book in books]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd158eb0-f79d-4746-bd18-856feb1ebe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_TYPES = [\"PERSON\", \"ORGANIZATION\", \"LOCATION\", \"GOD\", \"EVENT\", \"CREATURE\", \"WEAPON_OR_TOOL\"]\n",
    "def extract_entities(text: str) -> List[Dict]:\n",
    "    # Construct prompt\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": ch07_tools.create_extraction_prompt(ENTITY_TYPES, text)},\n",
    "    ]\n",
    "    # Make the LLM call\n",
    "    output = chat(messages, model = \"gpt-4o\")\n",
    "    # Construct JSON from output\n",
    "    return ch07_tools.parse_extraction_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23e32ad-1cc6-44cc-aa06-d3d142cdbfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Books:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Book 0:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "Book 0:   5%|▍         | 1/22 [00:04<01:36,  4.59s/it]\u001b[A\n",
      "Book 0:   9%|▉         | 2/22 [00:14<02:30,  7.51s/it]\u001b[A\n",
      "Book 0:  14%|█▎        | 3/22 [00:20<02:11,  6.93s/it]\u001b[A\n",
      "Book 0:  18%|█▊        | 4/22 [00:25<01:52,  6.27s/it]\u001b[A\n",
      "Book 0:  23%|██▎       | 5/22 [00:35<02:07,  7.53s/it]\u001b[A\n",
      "Book 0:  27%|██▋       | 6/22 [00:41<01:52,  7.00s/it]\u001b[A\n",
      "Book 0:  32%|███▏      | 7/22 [00:45<01:30,  6.05s/it]\u001b[A\n",
      "Book 0:  36%|███▋      | 8/22 [00:48<01:09,  4.94s/it]\u001b[A\n",
      "Book 0:  41%|████      | 9/22 [00:51<00:59,  4.61s/it]\u001b[A\n",
      "Book 0:  45%|████▌     | 10/22 [00:54<00:48,  4.07s/it]\u001b[A\n",
      "Book 0:  50%|█████     | 11/22 [00:59<00:47,  4.30s/it]\u001b[A\n",
      "Book 0:  55%|█████▍    | 12/22 [01:05<00:48,  4.86s/it]\u001b[A\n",
      "Book 0:  59%|█████▉    | 13/22 [01:15<00:57,  6.40s/it]\u001b[A\n",
      "Book 0:  64%|██████▎   | 14/22 [01:19<00:45,  5.66s/it]\u001b[A\n",
      "Book 0:  68%|██████▊   | 15/22 [01:23<00:36,  5.25s/it]\u001b[A\n",
      "Book 0:  73%|███████▎  | 16/22 [01:25<00:25,  4.21s/it]\u001b[A\n",
      "Book 0:  77%|███████▋  | 17/22 [01:31<00:23,  4.60s/it]\u001b[A\n",
      "Book 0:  82%|████████▏ | 18/22 [01:35<00:17,  4.39s/it]\u001b[A\n",
      "Book 0:  86%|████████▋ | 19/22 [01:39<00:13,  4.45s/it]\u001b[A\n",
      "Book 0:  91%|█████████ | 20/22 [01:45<00:09,  4.71s/it]\u001b[A\n",
      "Book 0:  95%|█████████▌| 21/22 [01:59<00:07,  7.73s/it]\u001b[A\n",
      "Book 0: 100%|██████████| 22/22 [02:03<00:00,  6.39s/it]\u001b[A\n",
      "Processing Books: 100%|██████████| 1/1 [02:03<00:00, 123.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Process only the first x books\n",
    "x = 1\n",
    "for book_i, book in enumerate(tqdm(chunked_books[:x], desc=\"Processing Books\")):\n",
    "    for chunk_i, chunk in enumerate(tqdm(book, desc=f\"Book {book_i}\", leave=False)):\n",
    "        nodes, relationships = extract_entities(chunk)\n",
    "        # Import nodes\n",
    "        neo4j_driver.execute_query(ch07_tools.import_nodes_query, data=nodes, book_id=book_i, text=chunk, chunk_id=chunk_i)\n",
    "        # Import relationships\n",
    "        neo4j_driver.execute_query(ch07_tools.import_relationships_query, data=relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5a61d4-11a0-4bc6-8d9f-48d7bdb6f17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing entities: 100%|██████████| 61/61 [01:21<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "candidates_to_summarize, _, _ = neo4j_driver.execute_query(\n",
    "    \"MATCH (e:__Entity__) WHERE size(e.description) > 1 RETURN e.name AS entity_name, e.description AS description_list\"\n",
    ")\n",
    "summaries = []\n",
    "for candidate in tqdm(candidates_to_summarize, desc=\"Summarizing entities\"):\n",
    "    # Construct prompt\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": ch07_tools.get_summarize_prompt(candidate[\"entity_name\"], candidate[\"description_list\"])},\n",
    "    ]\n",
    "    # Make the LLM call\n",
    "    summary = chat(messages, model = \"gpt-4o\")\n",
    "    summaries.append({\"entity\": candidate[\"entity_name\"], \"summary\": summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a11c0f-bb6a-4cce-bd48-0a4234618f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0x3109f48d0>, keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_driver.execute_query(\"\"\"\n",
    "UNWIND $data AS row\n",
    "MATCH (e:__Entity__ {name: row.entity})\n",
    "SET e.summary = row.summary\n",
    "\"\"\", data=summaries)\n",
    "\n",
    "# If there was only 1 description use that\n",
    "neo4j_driver.execute_query(\"\"\"\n",
    "MATCH (e:__Entity__)\n",
    "WHERE size(e.description) = 1\n",
    "SET e.summary = e.description[0]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66d59ea-04f4-42da-9a70-fcb3eb967383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 communities with distribution: {'min': 2, 'p5': 2, 'max': 19, 'p999': 19, 'p99': 19, 'p1': 2, 'p10': 2, 'p90': 19, 'p50': 5, 'p25': 2, 'p75': 9, 'p95': 19, 'mean': 8.125}\n"
     ]
    }
   ],
   "source": [
    "community_distribution = ch07_tools.calculate_communities(neo4j_driver)\n",
    "print(f\"There are {community_distribution['communityCount']} communities with distribution: {community_distribution['communityDistribution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4603b54-beb9-4158-b257-e3d934ad4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_info, _, _ = neo4j_driver.execute_query(\"\"\"\n",
    "MATCH (e:__Entity__)\n",
    "WHERE e.louvain IS NOT NULL\n",
    "WITH e.louvain AS louvain, collect(e) AS nodes\n",
    "WHERE size(nodes) > 1\n",
    "CALL apoc.path.subgraphAll(nodes[0], {\n",
    "\twhitelistNodes:nodes\n",
    "})\n",
    "YIELD relationships\n",
    "RETURN louvain AS communityId,\n",
    "       [n in nodes | {id: n.name, description: n.summary, type: [el in labels(n) WHERE el <> '__Entity__'][0]}] AS nodes,\n",
    "       [r in relationships | {start: startNode(r).name, type: type(r), end: endNode(r).name, description: r.description}] AS rels\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfacaf80-218d-4209-9a68-56c94b003f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing communities: 100%|██████████| 8/8 [01:02<00:00,  7.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EagerResult(records=[], summary=<neo4j._work.summary.ResultSummary object at 0x3125508d0>, keys=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities = []\n",
    "for community in tqdm(community_info, desc=\"Summarizing communities\"):\n",
    "    # Construct prompt\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": ch07_tools.get_summarize_community_prompt(community[\"nodes\"], community[\"rels\"])},\n",
    "    ]\n",
    "    # Make the LLM call\n",
    "    summary = chat(messages, model = \"gpt-4o\")\n",
    "    communities.append({\"community\": json.loads(ch07_tools.extract_json(summary)), \"communityId\": community[\"communityId\"], \"nodes\":[el['id'] for el in community[\"nodes\"]]})\n",
    "\n",
    "neo4j_driver.execute_query(ch07_tools.import_community_query, data=communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c363b-822b-4eb4-a4bd-3c0b6b0fa6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
