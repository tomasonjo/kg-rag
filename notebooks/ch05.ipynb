{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import json\n",
    "import utils\n",
    "\n",
    "reload(utils)\n",
    "\n",
    "chat = utils.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_rewrite_prompt = \"\"\"\n",
    "    You are an expert in language and understanding semantic meaning.\n",
    "    You read input from person and your job is to expand the input\n",
    "    into stand alone atomic questions.\n",
    "\n",
    "    You must return JSON using the template below.\n",
    "\n",
    "    Example:\n",
    "    Input: Who is Mick Jagger and how old is he?\n",
    "    Output: \n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"Who is Mick Jagger?\",\n",
    "            \"How old is Mick Jagger?\"\n",
    "        ]\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def query_rewrite(input: str) -> list[str]:\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": query_rewrite_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"The user question to rewrite: '{input}'\"},\n",
    "        ]\n",
    "        config = {\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "        }\n",
    "        output = chat(messages, model = \"gpt-3.5-turbo-0125\", config=config, )\n",
    "        try:\n",
    "            return json.loads(output)[\"questions\"]\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding JSON\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query rewrite results: [\"Who directed the movie 'The Godfather'?\", \"How long is the movie 'The Godfather'?\", \"What is the movie 'The Godfather' about?\"]\n"
     ]
    }
   ],
   "source": [
    "response = query_rewrite(\"Who directed the movie 'The Godfather', how long is it and what is it about?\")\n",
    "print(f\"Query rewrite results: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_update_prompt = \"\"\"\n",
    "    You are an expert at updating questions to make the them more atomic, specific and easier to find the answer for.\n",
    "    You do this by filling in missing information in the question, with the extra information provided to you in previous answers. \n",
    "    \n",
    "    You respond with the updated question that has all information in it.\n",
    "    Only edit the question if needed. If the original question already is atomic, specific and easy to answer, you keep the original.\n",
    "    Do not ask for more information than the original question. Only rephrase the question to make it more complete.\n",
    "    \n",
    "    JSON template to use:\n",
    "    {\n",
    "        \"question\": \"question1\"\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def query_update(input: str, answers: list[any]) -> str: \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": query_update_prompt},\n",
    "        *answers,\n",
    "        {\"role\": \"user\", \"content\": f\"The user question to rewrite: '{input}'\"},\n",
    "    ]\n",
    "    config = {\"response_format\": {\"type\": \"json_object\"}}\n",
    "    output = chat(messages, model = \"gpt-3.5-turbo-0125\", config=config, )\n",
    "    try:\n",
    "        return json.loads(output.choices[0].message.content)[\"question\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool_picker_prompt = \"\"\"\n",
    "    Your job is to chose the right tool needed to respond to the user question. \n",
    "    The available tools are provided to you in the prompt.\n",
    "    Make sure to pass the right and the complete arguments to the chosen tool.\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"capital_by_country\",\n",
    "            \"description\": \"Get the capital of a country by providing the country name\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"country\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The country name\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"country\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"country_by_capital\",\n",
    "            \"description\": \"Get the country name by providing the name of the capital city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"capital\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The capital city name\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"capital\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "def handle_tool_calls(tools: dict[str, any], llm_tool_calls: list[dict[str, any]]):\n",
    "    output = []\n",
    "    if llm_tool_calls:\n",
    "        for tool_call in llm_tool_calls:\n",
    "            function_to_call = tools[tool_call.function.name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            res = function_to_call(**function_args)\n",
    "            output.append(res)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(question: str, tools: dict[str, any], answers: list[dict[str, str]]):\n",
    "    llm_response = chat(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": tool_picker_prompt,\n",
    "            },\n",
    "            *answers,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"The user question to find a tool to answer: '{question}'\",\n",
    "            },\n",
    "        ],\n",
    "        model = \"gpt-3.5-turbo-0125\",\n",
    "        tools=tools,\n",
    "    )\n",
    "    tools_choices = llm_response.choices[0].message\n",
    "    llm_tool_calls = tools_choices[\"tool_calls\"]\n",
    "    return handle_tool_calls(tools, llm_tool_calls)\n",
    "\n",
    "def handle_user_input(input: str, answers: list[dict[str, str]] = []):\n",
    "    atomic_questions = query_rewrite(input)\n",
    "    for question in atomic_questions:\n",
    "        updated_question = query_update(question, answers)\n",
    "        response  = route_question(updated_question, tools, answers)\n",
    "        answers.append({\"role\": \"assistant\", \"content\": f\"For the question: '{updated_question}', we have the answer: '{json.dumps(response)}'\"})\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_critique_prompt = \"\"\"\n",
    "    You are an expert at identifying if questions has been fully answered or if there is an opportunity to enrich the answer.\n",
    "    The user will provide a question, and you will scan through the provided information to see if the question is answered.\n",
    "    If anything is missing from the answer, you will provide a set of new questions that can be asked to gather the missing information.\n",
    "    All new questions must be complete, atomic and specific.\n",
    "    However, if the provided information is enough to answer the original question, you will respond with an empty list.\n",
    "\n",
    "    JSON template to use for finding missing information:\n",
    "    {\n",
    "        \"questions\": [\"question1\", \"question2\"]\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def critique_answers(question: str, answers: list[dict[str, str]]) -> list[str]:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": answer_critique_prompt,\n",
    "        },\n",
    "        *answers,\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The original user question to answer: {question}\",\n",
    "        },\n",
    "    ]\n",
    "    config = {\"response_format\": {\"type\": \"json_object\"}}\n",
    "    output = chat(messages, model=\"gpt-3.5-turbo-0125\", config=config)\n",
    "    try:\n",
    "        return json.loads(output.choices[0].message.content)[\"questions\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = \"\"\"\n",
    "    Your job is to help the user with their questions.\n",
    "    You will receive user questions and information needed to answer the questions\n",
    "    If the information is missing to answer part of or the whole question, you will say that the information \n",
    "    is missing. You will only use the information provided to you in the prompt to answer the questions.\n",
    "    You are not allowed to make anything up or use external information.\n",
    "\"\"\"\n",
    "\n",
    "def main(input: str):\n",
    "    answers = handle_user_input(input)\n",
    "    critique = critique_answers(input, answers)\n",
    "\n",
    "    if critique:\n",
    "        answers = handle_user_input(\" \".join(critique), answers)\n",
    "\n",
    "    llm_response = chat(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": main_prompt},\n",
    "            *answers,\n",
    "            {\"role\": \"user\", \"content\": f\"The user question to answer: {input}\"},\n",
    "        ],\n",
    "        model=\"gpt-4-turbo\",\n",
    "    )\n",
    "\n",
    "    return llm_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
