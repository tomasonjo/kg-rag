{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import json\n",
    "from utils import chat, tool_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_rewrite_prompt = \"\"\"\n",
    "    You are an expert in language and understanding semantic meaning.\n",
    "    You read input from person and your job is to expand the input\n",
    "    into stand alone atomic questions.\n",
    "\n",
    "    You must return JSON using the template below.\n",
    "\n",
    "    Example:\n",
    "    Input: Who is Mick Jagger and how old is he?\n",
    "    Output: \n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"Who is Mick Jagger?\",\n",
    "            \"How old is Mick Jagger?\"\n",
    "        ]\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def query_rewrite(input: str) -> list[str]:\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": query_rewrite_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"The user question to rewrite: '{input}'\"},\n",
    "        ]\n",
    "        config = {\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "        }\n",
    "        output = chat(messages, model = \"gpt-4o\", config=config, )\n",
    "        try:\n",
    "            return json.loads(output)[\"questions\"]\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding JSON\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query rewrite results: [\"Who directed the movie 'The Godfather'?\", \"How long is the movie 'The Godfather'?\", \"What is the movie 'The Godfather' about?\"]\n"
     ]
    }
   ],
   "source": [
    "response = query_rewrite(\"Who directed the movie 'The Godfather', how long is it and what is it about?\")\n",
    "print(f\"Query rewrite results: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_update_prompt = \"\"\"\n",
    "    You are an expert at updating questions to make the them ask for one thing only, more atomic, specific and easier to find the answer for.\n",
    "    You do this by filling in missing information in the question, with the extra information provided to you in previous answers. \n",
    "    \n",
    "    You respond with the updated question that has all information in it.\n",
    "    Only edit the question if needed. If the original question already is atomic, specific and easy to answer, you keep the original.\n",
    "    Do not ask for more information than the original question. Only rephrase the question to make it more complete.\n",
    "    \n",
    "    JSON template to use:\n",
    "    {\n",
    "        \"question\": \"question1\"\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def query_update(input: str, answers: list[any]) -> str: \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": query_update_prompt},\n",
    "        *answers,\n",
    "        {\"role\": \"user\", \"content\": f\"The user question to rewrite: '{input}'\"},\n",
    "    ]\n",
    "    config = {\"response_format\": {\"type\": \"json_object\"}}\n",
    "    output = chat(messages, model = \"gpt-4o\", config=config, )\n",
    "    try:\n",
    "        return json.loads(output)[\"question\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ch05_tools\n",
    "\n",
    "tool_picker_prompt = \"\"\"\n",
    "    Your job is to chose the right tool needed to respond to the user question. \n",
    "    The available tools are provided to you in the prompt.\n",
    "    Make sure to pass the right and the complete arguments to the chosen tool.\n",
    "\"\"\"\n",
    "\n",
    "tools = {\n",
    "    \"movie_info_by_title\": {\n",
    "        \"description\": ch05_tools.movie_info_by_title_description,\n",
    "        \"function\": ch05_tools.movie_info_by_title\n",
    "    },\n",
    "    \"movies_info_by_actor\": {\n",
    "        \"description\": ch05_tools.movies_info_by_actor_description,\n",
    "        \"function\": ch05_tools.movies_info_by_actor\n",
    "    },\n",
    "    \"text2cypher\": {\n",
    "        \"description\": ch05_tools.text2cypher_description,\n",
    "        \"function\": ch05_tools.text2cypher\n",
    "    },\n",
    "    \"answer_given\": {\n",
    "        \"description\": ch05_tools.answer_given_description,\n",
    "        \"function\": ch05_tools.answer_given\n",
    "    }\n",
    "}\n",
    "\n",
    "def handle_tool_calls(tools: dict[str, any], llm_tool_calls: list[dict[str, any]]):\n",
    "    output = []\n",
    "    if llm_tool_calls:\n",
    "        for tool_call in llm_tool_calls:\n",
    "            function_to_call = tools[tool_call.function.name][\"function\"]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            res = function_to_call(**function_args)\n",
    "            output.append(res)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(question: str, tools: dict[str, any], answers: list[dict[str, str]]):\n",
    "    llm_tool_calls = tool_choice(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": tool_picker_prompt,\n",
    "            },\n",
    "            *answers,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"The user question to find a tool to answer: '{question}'\",\n",
    "            },\n",
    "        ],\n",
    "        model = \"gpt-4o\",\n",
    "        tools=[tool[\"description\"] for tool in tools.values()],\n",
    "    )\n",
    "    return handle_tool_calls(tools, llm_tool_calls)\n",
    "\n",
    "def handle_user_input(input: str, answers: list[dict[str, str]] = []):\n",
    "    atomic_questions = query_rewrite(input)\n",
    "    for question in atomic_questions:\n",
    "        updated_question = query_update(question, answers)\n",
    "        response  = route_question(updated_question, tools, answers)\n",
    "        answers.append({\"role\": \"assistant\", \"content\": f\"For the question: '{updated_question}', we have the answer: '{json.dumps(response)}'\"})\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_critique_prompt = \"\"\"\n",
    "    You are an expert at identifying if questions has been fully answered or if there is an opportunity to enrich the answer.\n",
    "    The user will provide a question, and you will scan through the provided information to see if the question is answered.\n",
    "    If anything is missing from the answer, you will provide a set of new questions that can be asked to gather the missing information.\n",
    "    All new questions must be complete, atomic and specific.\n",
    "    However, if the provided information is enough to answer the original question, you will respond with an empty list.\n",
    "\n",
    "    JSON template to use for finding missing information:\n",
    "    {\n",
    "        \"questions\": [\"question1\", \"question2\"]\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def critique_answers(question: str, answers: list[dict[str, str]]) -> list[str]:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": answer_critique_prompt,\n",
    "        },\n",
    "        *answers,\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The original user question to answer: {question}\",\n",
    "        },\n",
    "    ]\n",
    "    config = {\"response_format\": {\"type\": \"json_object\"}}\n",
    "    output = chat(messages, model=\"gpt-4o\", config=config)\n",
    "    try:\n",
    "        return json.loads(output)[\"questions\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_prompt = \"\"\"\n",
    "    Your job is to help the user with their questions.\n",
    "    You will receive user questions and information needed to answer the questions\n",
    "    If the information is missing to answer part of or the whole question, you will say that the information \n",
    "    is missing. You will only use the information provided to you in the prompt to answer the questions.\n",
    "    You are not allowed to make anything up or use external information.\n",
    "\"\"\"\n",
    "\n",
    "def main(input: str):\n",
    "    answers = handle_user_input(input)\n",
    "    critique = critique_answers(input, answers)\n",
    "\n",
    "    if critique:\n",
    "        answers = handle_user_input(\" \".join(critique), answers)\n",
    "\n",
    "    llm_response = chat(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": main_prompt},\n",
    "            *answers,\n",
    "            {\"role\": \"user\", \"content\": f\"The user question to answer: {input}\"},\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main response: The main actor in the movie \"The Matrix\" is Keanu Reeves. Other movies that Keanu Reeves is in include:\n",
      "\n",
      "1. \"The Matrix Reloaded\" (2003)\n",
      "2. \"The Matrix Revolutions\" (2003)\n",
      "3. \"The Devil's Advocate\" (1997)\n",
      "4. \"The Replacements\" (2000)\n",
      "5. \"Johnny Mnemonic\" (1995)\n",
      "6. \"Something's Gotta Give\" (2003)\n"
     ]
    }
   ],
   "source": [
    "response = main(\"Who's the main actor in the movie Matrix and what other movies is that person in?\")\n",
    "print(f\"Main response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next response: The information provided indicates there are 28 unique directors and 8 unique producers in the database.\n"
     ]
    }
   ],
   "source": [
    "next_res = main(\"How many directors and producers are in the database?\")\n",
    "print(f\"Next response: {next_res}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
